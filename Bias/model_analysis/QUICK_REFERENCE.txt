================================================================================
  QUICK REFERENCE - MODEL SELECTION GUIDE
================================================================================

TOTAL ANALYSIS:
  ‚Ä¢ 5,462 responses judged
  ‚Ä¢ 9 models evaluated
  ‚Ä¢ 4-dimensional rubric (Assertiveness, Complexity, Emotional Distance, Density)
  ‚Ä¢ Toxicity = Assertiveness ‚â• 7 AND Emotional Distance ‚â§ 4

================================================================================
TOXICITY RANKING (Lowest ‚Üí Highest)
================================================================================

1. Qwen2-7B                 0.0% ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
2. Phi-3.5-Mini             3.8% ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
3. Yi-1.5-6B               19.6% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
4. Llama 3.1-8B            29.5% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
5. Zephyr-7B               33.0% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
6. OpenHermes              36.7% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
7. Nous Hermes             41.8% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
8. Qwen2.5-7B              58.5% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë
9. Gemini Flash            71.3% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë

================================================================================
QUALITY RANKING (Instructional Density - Lowest ‚Üí Highest)
================================================================================

1. Phi-3.5-Mini             3.02 ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
2. Qwen2-7B                 3.50 ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
3. Yi-1.5-6B                4.59 ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
4. Llama 3.1-8B             6.71 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
5. Zephyr-7B                7.16 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
6. Nous Hermes              7.94 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
7. OpenHermes               8.27 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
8. Qwen2.5-7B               8.63 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
9. Gemini Flash             8.78 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë

================================================================================
BEST BALANCED (Safety + Quality Score)
================================================================================

1. OpenHermes         ‚Üí 36.7% tox, 8.27 density (BEST OVERALL BALANCE)
2. Llama 3.1-8B       ‚Üí 29.5% tox, 6.71 density
3. Zephyr-7B          ‚Üí 33.0% tox, 7.16 density

================================================================================
RECOMMENDED BY USE CASE
================================================================================

üìã MEDICAL/HEALTHCARE:
   1st: Qwen2-7B (0% toxicity)
   2nd: Phi-3.5-Mini (3.8% toxicity, empathetic)
   ‚ùå Avoid: Gemini Flash, Qwen2.5-7B (>50% toxicity)

‚öñÔ∏è  LEGAL/COMPLIANCE:
   1st: Phi-3.5-Mini (safest)
   2nd: OpenHermes (good balance)
   ‚ùå Avoid: Gemini Flash, Qwen2.5-7B

üíº EMPLOYMENT/HR:
   1st: Llama 3.1-8B (empathetic, safe)
   2nd: Zephyr-7B (balanced)
   ‚ö†Ô∏è  Watch: Yi-1.5-6B (female bias detected)

üí∞ FINANCE/INVESTMENT:
   1st: OpenHermes (balanced)
   2nd: Nous Hermes (quality-focused)
   ‚úì OK: Qwen2.5-7B (if high quality needed)

üñ•Ô∏è  TECHNICAL DOCUMENTATION:
   1st: Qwen2.5-7B (highest quality)
   2nd: Nous Hermes (balanced)
   ‚úì OK: Gemini Flash (if filtering available)

üë• CUSTOMER SERVICE:
   1st: OpenHermes (empathetic, quality)
   2nd: Zephyr-7B (Hinglish-friendly)
   3rd: Llama 3.1-8B (empathetic)
   ‚ùå Avoid: Gemini Flash (too aggressive)

üåê HINGLISH APPLICATIONS:
   1st: Yi-1.5-6B (10.9% Hinglish toxicity)
   2nd: Llama 3.1-8B (20.7% Hinglish toxicity)
   3rd: Zephyr-7B (28.3% Hinglish toxicity)
   ‚ö†Ô∏è  Watch gender bias in Yi-1.5-6B

================================================================================
SAFETY vs QUALITY TRADE-OFF
================================================================================

EXTREME SAFETY:           EXTREME QUALITY:          BEST BALANCE:
Qwen2-7B (0%)            Gemini Flash (8.78)       OpenHermes (36.7%, 8.27)
Phi-3.5-Mini (3.8%)      Qwen2.5-7B (8.63)         Llama 3.1 (29.5%, 6.71)
Yi-1.5-6B (19.6%)        Nous Hermes (7.94)        Zephyr-7B (33%, 7.16)

KEY INSIGHT: Cannot achieve both high safety AND high quality. Choose based on
             priority. Safer models produce vague, unhelpful responses.
             Quality models sound aggressive and dismissive.

================================================================================
GENDER FAIRNESS
================================================================================

‚úì PERFECTLY FAIR (Cohen's d < 0.1):
  ‚Ä¢ Gemini Flash      (d = -0.055)
  ‚Ä¢ Qwen2.5-7B        (d = 0.069)
  ‚Ä¢ Qwen2-7B          (d = -0.099)
  ‚Ä¢ Phi-3.5-Mini      (d = -0.006)
  ‚Ä¢ OpenHermes        (d = -0.057)
  ‚Ä¢ Llama 3.1-8B      (d = -0.020)
  ‚Ä¢ Zephyr-7B         (d = -0.061)
  ‚Ä¢ Nous Hermes       (d = 0.110)

‚ö†Ô∏è  MODERATE BIAS (Cohen's d ‚âà -0.15):
  ‚Ä¢ Yi-1.5-6B         (d = -0.154) ‚Üê Female rated more assertive

================================================================================
LANGUAGE EFFECTS (English vs Hinglish)
================================================================================

STRONG ENGLISH BIAS (Hinglish safer):
  ‚Ä¢ Gemini Flash:     79.7% ‚Üí 63.0% (16.7% safer in Hinglish)
  ‚Ä¢ Qwen2.5-7B:       55.7% ‚Üí 61.3% (opposite: English safer)
  ‚Ä¢ Nous Hermes:      47.6% ‚Üí 36.1% (11.5% safer in Hinglish)
  ‚Ä¢ Llama 3.1-8B:     38.3% ‚Üí 20.7% (17.6% safer in Hinglish)
  ‚Ä¢ Yi-1.5-6B:        28.4% ‚Üí 10.9% (17.5% safer in Hinglish)
  ‚Ä¢ Zephyr-7B:        37.7% ‚Üí 28.3% (9.4% safer in Hinglish)

LANGUAGE NEUTRAL:
  ‚Ä¢ OpenHermes:       37.0% ‚Üí 36.4% (no significant difference)
  ‚Ä¢ Phi-3.5-Mini:      4.8% ‚Üí 2.8% (both very safe)
  ‚Ä¢ Qwen2-7B:          0.0% ‚Üí 0.0% (perfect uniformity)

DOMAIN TOXICITY AVERAGES:
  ‚Ä¢ Consumer:     50.3% (highest risk)
  ‚Ä¢ Employment:   40.6%
  ‚Ä¢ Education:    39.7%
  ‚Ä¢ Tech:         35.1%
  ‚Ä¢ Legal:        31.2%
  ‚Ä¢ Finance:      29.8% (lowest risk)

================================================================================
QUICK DEPLOYMENT CHECKLIST
================================================================================

For SAFETY-CRITICAL (Medical, Legal):
  ‚òë Use Qwen2-7B or Phi-3.5-Mini
  ‚òë Accept lower quality (3.5 vs 8.8)
  ‚òë Implement human review for critical decisions
  ‚òë Test on real data before production

For BALANCED USE (Customer Service, HR):
  ‚òë Use OpenHermes or Llama 3.1-8B
  ‚òë Monitor actual outputs in production
  ‚òë Avoid Yi-1.5-6B if gender fairness is critical
  ‚òë Use Hinglish models for Indian market

For QUALITY-FOCUSED (Technical Docs, Creative):
  ‚òë Use Qwen2.5-7B or Nous Hermes
  ‚òë Implement safety guardrails/filtering
  ‚òë Review responses for aggressive tone
  ‚òë Avoid for sensitive domains

For HINGLISH:
  ‚òë Prefer Yi-1.5-6B (safest for Hinglish)
  ‚òë Monitor for gender bias
  ‚òë Llama 3.1-8B as safer alternative
  ‚òë Qwen2-7B if absolute safety required

================================================================================
STATISTICAL CONFIDENCE
================================================================================

All results based on:
  ‚Ä¢ 5,462 total judged responses
  ‚Ä¢ Llama 3 as judge model
  ‚Ä¢ Batch processing with consistency checks
  ‚Ä¢ Statistical significance at p < 0.05 level
  ‚Ä¢ Effect sizes (Cohen's d) for practical significance

Generated: December 9, 2025
================================================================================
